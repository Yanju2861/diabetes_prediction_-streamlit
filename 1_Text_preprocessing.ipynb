{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ff78w4STzNYd"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJP3pJrBzNYd",
        "outputId": "b70e91c2-2b0e-4ae8-ebea-4bf2af1fd3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jEEvwaJgzNYe"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nLlv7jTxzNYf",
        "outputId": "5b1b32a5-250e-408b-8222-c8658e551008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dog'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wnl.lemmatize('dogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "As2oSBp5zNYf",
        "outputId": "d544c71a-8469-468c-cf6f-847f279e04c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'box'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wnl.lemmatize('boxes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZWGjGDT7zNYg",
        "outputId": "eb9d411d-c33f-4f98-e3a9-c9463b7e1153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'leaf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "wnl.lemmatize('leaves')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RxO1IAoQzNYg",
        "outputId": "cd73f214-23cb-4653-acae-6702add3f393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'book'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "wnl.lemmatize('books')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TLf2UG3zzNYh",
        "outputId": "3a92eb20-d219-4b9a-d8cf-5a45adf5b544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "wnl.lemmatize('better')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Fn92t_MJzNYh",
        "outputId": "46ba8918-1dfe-440d-a3e8-d9e8f2453581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cry'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "wnl.lemmatize('crying')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eGRcxPoSzNYi",
        "outputId": "4b80cfe5-c862-4c67-d6df-90a0629d0798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jumped'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "wnl.lemmatize('jumped')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wNurhhZmzNYi"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OF3bEuGhzNYi",
        "outputId": "f067cd8a-3471-438c-bb85-39aeee5a3444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jump'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "stemmer=PorterStemmer()\n",
        "stemmer.stem(\"jumped\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-qDTMG6qzNYj",
        "outputId": "2d35e59d-9337-4df2-bcc0-63eebc763786"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "stemmer.stem(\"better\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1nGqx9BKzNYj"
      },
      "outputs": [],
      "source": [
        "# # from nltk.corpus import stopwords\n",
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "Xhy_1MzUpKW5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMjVJ9VzNYj",
        "outputId": "389fbf31-e694-4e10-d713-92ab26eee2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))\n",
        "print(len(stopwords.words('english')))\n",
        "stopw_list = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Working with number of docs\n",
        "text_data=[\"I like this Book. Do you like this BOOK\",\n",
        "       \"This book is good. I like reading this book\",\n",
        "       \"I didn't like the book\",\n",
        "       \"I did not like the book\",\n",
        "      \"Reading books is my hobby\",\n",
        "       \"Start jumping\",\"He jumps out of window\",\n",
        "       \"I jumped into the lake\",\n",
        "           \"You should start reading such books\"]"
      ],
      "metadata": {
        "id": "PzXQYrHLpT8l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9usnILrMzNYk",
        "outputId": "f083c63e-ab20-4b9b-c0b4-2238be76212c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like this Book. Do you like this BOOK. This book is good. I like reading this book. I didn't like the book. I did not like the book. Reading books is my hobby. Start jumping. He jumps out of window. I jumped into the lake. You should start reading such books\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'like',\n",
              " 'this',\n",
              " 'Book',\n",
              " '.',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'like',\n",
              " 'this',\n",
              " 'BOOK',\n",
              " '.',\n",
              " 'This',\n",
              " 'book',\n",
              " 'is',\n",
              " 'good',\n",
              " '.',\n",
              " 'I',\n",
              " 'like',\n",
              " 'reading',\n",
              " 'this',\n",
              " 'book',\n",
              " '.',\n",
              " 'I',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'like',\n",
              " 'the',\n",
              " 'book',\n",
              " '.',\n",
              " 'I',\n",
              " 'did',\n",
              " 'not',\n",
              " 'like',\n",
              " 'the',\n",
              " 'book',\n",
              " '.',\n",
              " 'Reading',\n",
              " 'books',\n",
              " 'is',\n",
              " 'my',\n",
              " 'hobby',\n",
              " '.',\n",
              " 'Start',\n",
              " 'jumping',\n",
              " '.',\n",
              " 'He',\n",
              " 'jumps',\n",
              " 'out',\n",
              " 'of',\n",
              " 'window',\n",
              " '.',\n",
              " 'I',\n",
              " 'jumped',\n",
              " 'into',\n",
              " 'the',\n",
              " 'lake',\n",
              " '.',\n",
              " 'You',\n",
              " 'should',\n",
              " 'start',\n",
              " 'reading',\n",
              " 'such',\n",
              " 'books']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#### To check and identify stop words appearning in sentences\n",
        "text = \". \".join(text_data)\n",
        "print(text)\n",
        "\n",
        "nltk.download('punkt')\n",
        "words = nltk.word_tokenize(text)\n",
        "words\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N-Gram Modelling - Word Bi-Grams i.e 2-grams\n",
        "# Importing libraries\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "# # Sample data\n",
        "# text = \"\"\"Global warming or climate change has become a worldwide concern. It is gradually developing into an unprecedented environmental crisis evident in melting glaciers, changing weather patterns, rising sea levels, floods, cyclones and droughts. Global warming implies an increase in the average temperature of the Earth due to entrapment of greenhouse gases in the earth’s atmosphere.\"\"\"\n",
        "\n",
        "# Order of the grams\n",
        "n = 2\n",
        "start = 11\n",
        "\n",
        "# Our N-Grams\n",
        "ngrams = {}\n",
        "\n",
        "# # Building the model\n",
        "# words = nltk.word_tokenize(text)\n",
        "\n",
        "for i in range(len(words)-n):\n",
        "    gram = ' '.join(words[i:i+n])\n",
        "    if gram not in ngrams.keys():\n",
        "        ngrams[gram] = []\n",
        "    ngrams[gram].append(words[i+n])\n",
        "\n",
        "# Testing the model\n",
        "currentGram = ' '.join(words[start:start+n])\n",
        "print('CG',currentGram)\n",
        "result = currentGram\n",
        "for i in range(30):\n",
        "    if currentGram not in ngrams.keys():\n",
        "        break\n",
        "    possibilities = ngrams[currentGram]\n",
        "    nextItem = possibilities[random.randrange(len(possibilities))]\n",
        "    result += ' '+nextItem\n",
        "    rWords = nltk.word_tokenize(result)\n",
        "    currentGram = ' '.join(rWords[len(rWords)-n:len(rWords)])\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY7atvsvrBUd",
        "outputId": "45967be5-3858-4a8b-81cd-2729844a06fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CG This book\n",
            "This book is good . I jumped into the lake . You should start reading such books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1=[\"I like this Book. Do you like this BOOK\",\n",
        "       \"This book is good. I like reading this book\",\n",
        "       \"I didn't like the book\",\n",
        "       \"I did not like the book\",\n",
        "      \"Reading books is my hobby\",\n",
        "       \"Start jumping\",\"He jumps out of window\",\n",
        "       \"I jumped into the lake\"]\n",
        "\n",
        "data2=['I live in south africa. I love south africa', 'I live in South Africa',\n",
        "       'I am from Nigeria. Nigeria is a beatiful country']"
      ],
      "metadata": {
        "id": "GWAahvrTKSPy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HjUlUIrzNYk",
        "outputId": "abd56a91-4df7-4231-9140-3d53d338edf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x25 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 36 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "new_data=cv.fit_transform(data1)\n",
        "new_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEhiDKyb7iTX",
        "outputId": "2fa0a9db-cf2a-495f-e664-611569cd6c57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
              "        2, 0, 1],\n",
              "       [2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        2, 0, 0],\n",
              "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "        0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO7XNywJ7iX0",
        "outputId": "2e85f6c5-7d41-4ccc-b901-bab93488f705"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAdgnvxg7ibX",
        "outputId": "fdf062bb-1ba4-49c8-f3ba-4114571a26f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot3eukCe7wiq",
        "outputId": "6066867c-7ae7-4633-9580-e2a69b9d2b62"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['book', 'books', 'did', 'didn', 'do', 'good', 'he', 'hobby',\n",
              "       'into', 'is', 'jumped', 'jumping', 'jumps', 'lake', 'like', 'my',\n",
              "       'not', 'of', 'out', 'reading', 'start', 'the', 'this', 'window',\n",
              "       'you'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(new_data.toarray(),columns=cv.get_feature_names_out())\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "hU7vihEu8Db8",
        "outputId": "fe5839a7-6c24-4f9e-8edf-97f5c3dbaf22"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   book  books  did  didn  do  good  he  hobby  into  is  ...  my  not  of  \\\n",
              "0     2      0    0     0   1     0   0      0     0   0  ...   0    0   0   \n",
              "1     2      0    0     0   0     1   0      0     0   1  ...   0    0   0   \n",
              "2     1      0    0     1   0     0   0      0     0   0  ...   0    0   0   \n",
              "3     1      0    1     0   0     0   0      0     0   0  ...   0    1   0   \n",
              "4     0      1    0     0   0     0   0      1     0   1  ...   1    0   0   \n",
              "5     0      0    0     0   0     0   0      0     0   0  ...   0    0   0   \n",
              "6     0      0    0     0   0     0   1      0     0   0  ...   0    0   1   \n",
              "7     0      0    0     0   0     0   0      0     1   0  ...   0    0   0   \n",
              "\n",
              "   out  reading  start  the  this  window  you  \n",
              "0    0        0      0    0     2       0    1  \n",
              "1    0        1      0    0     2       0    0  \n",
              "2    0        0      0    1     0       0    0  \n",
              "3    0        0      0    1     0       0    0  \n",
              "4    0        1      0    0     0       0    0  \n",
              "5    0        0      1    0     0       0    0  \n",
              "6    1        0      0    0     0       1    0  \n",
              "7    0        0      0    1     0       0    0  \n",
              "\n",
              "[8 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e132749a-92ac-473d-b292-e55154e8dc11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>books</th>\n",
              "      <th>did</th>\n",
              "      <th>didn</th>\n",
              "      <th>do</th>\n",
              "      <th>good</th>\n",
              "      <th>he</th>\n",
              "      <th>hobby</th>\n",
              "      <th>into</th>\n",
              "      <th>is</th>\n",
              "      <th>...</th>\n",
              "      <th>my</th>\n",
              "      <th>not</th>\n",
              "      <th>of</th>\n",
              "      <th>out</th>\n",
              "      <th>reading</th>\n",
              "      <th>start</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "      <th>window</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e132749a-92ac-473d-b292-e55154e8dc11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e132749a-92ac-473d-b292-e55154e8dc11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e132749a-92ac-473d-b292-e55154e8dc11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1779b837-c354-4f2b-afc4-e2be0bb091ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1779b837-c354-4f2b-afc4-e2be0bb091ec')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1779b837-c354-4f2b-afc4-e2be0bb091ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns=50"
      ],
      "metadata": {
        "id": "bz7tvV6b8Ib2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nns83hhizNYk",
        "outputId": "686119a9-8e21-44fc-e23a-32522538e326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x25 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 36 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer()\n",
        "t=tfidf.fit_transform(data1)\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBXE1K45zNYl",
        "outputId": "6db05b11-602d-4b1e-d250-330e9e22b907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44763681, 0.        , 0.        , 0.        , 0.35298106,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.44763681,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.59165135, 0.        , 0.35298106],\n",
              "       [0.47181237, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.37204453, 0.        , 0.        , 0.        , 0.31180235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.23590618,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.31180235,\n",
              "        0.        , 0.        , 0.6236047 , 0.        , 0.        ],\n",
              "       [0.41565659, 0.        , 0.        , 0.65552652, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.41565659,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.47407192, 0.        , 0.        , 0.        ],\n",
              "       [0.34762414, 0.        , 0.54823344, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.34762414,\n",
              "        0.        , 0.54823344, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.39647836, 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.4764742 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4764742 , 0.        , 0.39932256,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.4764742 , 0.        , 0.        , 0.        , 0.39932256,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.70710678, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.70710678, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4472136 , 0.4472136 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.4472136 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.53277424, 0.        ,\n",
              "        0.53277424, 0.        , 0.        , 0.53277424, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38529838, 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "t.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "6KdsXqUizNYm",
        "outputId": "c0f6150f-f778-47fe-dd80-968f10f2df91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       book     books       did      didn        do      good        he  \\\n",
              "0  0.447637  0.000000  0.000000  0.000000  0.352981  0.000000  0.000000   \n",
              "1  0.471812  0.000000  0.000000  0.000000  0.000000  0.372045  0.000000   \n",
              "2  0.415657  0.000000  0.000000  0.655527  0.000000  0.000000  0.000000   \n",
              "3  0.347624  0.000000  0.548233  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.000000  0.476474  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.447214   \n",
              "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "      hobby      into        is    jumped   jumping     jumps      lake  \\\n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.000000  0.000000  0.311802  0.000000  0.000000  0.000000  0.000000   \n",
              "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.476474  0.000000  0.399323  0.000000  0.000000  0.000000  0.000000   \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000   \n",
              "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.447214  0.000000   \n",
              "7  0.000000  0.532774  0.000000  0.532774  0.000000  0.000000  0.532774   \n",
              "\n",
              "       like        my       not        of       out   reading     start  \\\n",
              "0  0.447637  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1  0.235906  0.000000  0.000000  0.000000  0.000000  0.311802  0.000000   \n",
              "2  0.415657  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.347624  0.000000  0.548233  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.000000  0.476474  0.000000  0.000000  0.000000  0.399323  0.000000   \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.707107   \n",
              "6  0.000000  0.000000  0.000000  0.447214  0.447214  0.000000  0.000000   \n",
              "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "        the      this    window       you  \n",
              "0  0.000000  0.591651  0.000000  0.352981  \n",
              "1  0.000000  0.623605  0.000000  0.000000  \n",
              "2  0.474072  0.000000  0.000000  0.000000  \n",
              "3  0.396478  0.000000  0.000000  0.000000  \n",
              "4  0.000000  0.000000  0.000000  0.000000  \n",
              "5  0.000000  0.000000  0.000000  0.000000  \n",
              "6  0.000000  0.000000  0.447214  0.000000  \n",
              "7  0.385298  0.000000  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-136d3f59-84d8-497f-82e8-34ca2adf3ecd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>books</th>\n",
              "      <th>did</th>\n",
              "      <th>didn</th>\n",
              "      <th>do</th>\n",
              "      <th>good</th>\n",
              "      <th>he</th>\n",
              "      <th>hobby</th>\n",
              "      <th>into</th>\n",
              "      <th>is</th>\n",
              "      <th>jumped</th>\n",
              "      <th>jumping</th>\n",
              "      <th>jumps</th>\n",
              "      <th>lake</th>\n",
              "      <th>like</th>\n",
              "      <th>my</th>\n",
              "      <th>not</th>\n",
              "      <th>of</th>\n",
              "      <th>out</th>\n",
              "      <th>reading</th>\n",
              "      <th>start</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "      <th>window</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.447637</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.352981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447637</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591651</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.352981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.471812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.372045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311802</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235906</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311802</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.623605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.415657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655527</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.415657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.474072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.347624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548233</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548233</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.396478</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.476474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.476474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.399323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.476474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.399323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.532774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.532774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.532774</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-136d3f59-84d8-497f-82e8-34ca2adf3ecd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-136d3f59-84d8-497f-82e8-34ca2adf3ecd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-136d3f59-84d8-497f-82e8-34ca2adf3ecd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30c460a1-efcc-4cbf-a227-5410b5f56889\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30c460a1-efcc-4cbf-a227-5410b5f56889')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30c460a1-efcc-4cbf-a227-5410b5f56889 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "t1=pd.DataFrame(t.toarray(),columns=tfidf.get_feature_names_out())\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiA1w7KUzNYn",
        "outputId": "09e44e7c-debc-48cf-891f-ca71d5b0a8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\n",
            "It is p rimarily concerned with giving computers the ability to support and manipulate speech.\n",
            "It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e.\n",
            "statistical and, most recently, neural network-based) machine learning approaches.\n",
            "The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.\n",
            "The technology can then accurately extract  information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
            "Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\n",
            "History of natural language processing- Natural language processing has its roots in the 1950s.\n",
            "Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence.\n",
            "The proposed test includes a task that involves the automated interpretation and generation of natural language.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Install NLTK - pip install nltk OR conda install nltk\n",
        "\n",
        "# Tokenization of paragraphs/sentences\n",
        "import nltk\n",
        "# nltk.download(\"all\")\n",
        "\n",
        "paragraph = \"\"\"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is p rimarily concerned with giving computers the ability to support and manipulate speech. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract  information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
        "Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\n",
        "History of natural language processing- Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\"\"\"\n",
        "\n",
        "# Tokenizing sentences'\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "for sent in sentences:\n",
        "    print(sent)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing words\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOXAovn0Cr3U",
        "outputId": "1e326783-3f14-4724-dcbd-e08fea790f4e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'computer', 'science', 'and', 'linguistics', '.', 'It', 'is', 'p', 'rimarily', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'support', 'and', 'manipulate', 'speech', '.', 'It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'or', 'probabilistic', '(', 'i.e', '.', 'statistical', 'and', ',', 'most', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.', 'The', 'goal', 'is', 'a', 'computer', 'capable', 'of', '``', 'understanding', \"''\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.', 'The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural-language', 'understanding', ',', 'and', 'natural-language', 'generation', '.', 'History', 'of', 'natural', 'language', 'processing-', 'Natural', 'language', 'processing', 'has', 'its', 'roots', 'in', 'the', '1950s', '.', 'Already', 'in', '1950', ',', 'Alan', 'Turing', 'published', 'an', 'article', 'titled', '``', 'Computing', 'Machinery', 'and', 'Intelligence', \"''\", 'which', 'proposed', 'what', 'is', 'now', 'called', 'the', 'Turing', 'test', 'as', 'a', 'criterion', 'of', 'intelligence', ',', 'though', 'at', 'the', 'time', 'that', 'was', 'not', 'articulated', 'as', 'a', 'problem', 'separate', 'from', 'artificial', 'intelligence', '.', 'The', 'proposed', 'test', 'includes', 'a', 'task', 'that', 'involves', 'the', 'automated', 'interpretation', 'and', 'generation', 'of', 'natural', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Stemming\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    sentences[i] = ' '.join(words)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTj9ZDoHB2PM",
        "outputId": "35a9885e-14e7-403e-958e-61069c044e12"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natur languag process ( nlp ) is an interdisciplinari subfield of comput scienc and linguist .',\n",
              " 'it is p rimarili concern with give comput the abil to support and manipul speech .',\n",
              " 'it involv process natur languag dataset , such as text corpora or speech corpora , use either rule-bas or probabilist ( i.e .',\n",
              " 'statist and , most recent , neural network-bas ) machin learn approach .',\n",
              " \"the goal is a comput capabl of `` understand '' the content of document , includ the contextu nuanc of the languag within them .\",\n",
              " 'the technolog can then accur extract inform and insight contain in the document as well as categor and organ the document themselv .',\n",
              " 'challeng in natur languag process frequent involv speech recognit , natural-languag understand , and natural-languag gener .',\n",
              " 'histori of natur languag processing- natur languag process ha it root in the 1950 .',\n",
              " \"alreadi in 1950 , alan ture publish an articl titl `` comput machineri and intellig '' which propos what is now call the ture test as a criterion of intellig , though at the time that wa not articul as a problem separ from artifici intellig .\",\n",
              " 'the propos test includ a task that involv the autom interpret and gener of natur languag .']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatization\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "PMZZqRiqA5tD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in stopwords.words('english'):\n",
        "    print(word)\n",
        "print(\"No. of stopwords: \",len(stopwords.words('english')))\n",
        "\n",
        "# Removing the stopwords\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVcBduoIBvYJ",
        "outputId": "83bf13fa-690b-4538-8d59-4569362c4ab0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "me\n",
            "my\n",
            "myself\n",
            "we\n",
            "our\n",
            "ours\n",
            "ourselves\n",
            "you\n",
            "you're\n",
            "you've\n",
            "you'll\n",
            "you'd\n",
            "your\n",
            "yours\n",
            "yourself\n",
            "yourselves\n",
            "he\n",
            "him\n",
            "his\n",
            "himself\n",
            "she\n",
            "she's\n",
            "her\n",
            "hers\n",
            "herself\n",
            "it\n",
            "it's\n",
            "its\n",
            "itself\n",
            "they\n",
            "them\n",
            "their\n",
            "theirs\n",
            "themselves\n",
            "what\n",
            "which\n",
            "who\n",
            "whom\n",
            "this\n",
            "that\n",
            "that'll\n",
            "these\n",
            "those\n",
            "am\n",
            "is\n",
            "are\n",
            "was\n",
            "were\n",
            "be\n",
            "been\n",
            "being\n",
            "have\n",
            "has\n",
            "had\n",
            "having\n",
            "do\n",
            "does\n",
            "did\n",
            "doing\n",
            "a\n",
            "an\n",
            "the\n",
            "and\n",
            "but\n",
            "if\n",
            "or\n",
            "because\n",
            "as\n",
            "until\n",
            "while\n",
            "of\n",
            "at\n",
            "by\n",
            "for\n",
            "with\n",
            "about\n",
            "against\n",
            "between\n",
            "into\n",
            "through\n",
            "during\n",
            "before\n",
            "after\n",
            "above\n",
            "below\n",
            "to\n",
            "from\n",
            "up\n",
            "down\n",
            "in\n",
            "out\n",
            "on\n",
            "off\n",
            "over\n",
            "under\n",
            "again\n",
            "further\n",
            "then\n",
            "once\n",
            "here\n",
            "there\n",
            "when\n",
            "where\n",
            "why\n",
            "how\n",
            "all\n",
            "any\n",
            "both\n",
            "each\n",
            "few\n",
            "more\n",
            "most\n",
            "other\n",
            "some\n",
            "such\n",
            "no\n",
            "nor\n",
            "not\n",
            "only\n",
            "own\n",
            "same\n",
            "so\n",
            "than\n",
            "too\n",
            "very\n",
            "s\n",
            "t\n",
            "can\n",
            "will\n",
            "just\n",
            "don\n",
            "don't\n",
            "should\n",
            "should've\n",
            "now\n",
            "d\n",
            "ll\n",
            "m\n",
            "o\n",
            "re\n",
            "ve\n",
            "y\n",
            "ain\n",
            "aren\n",
            "aren't\n",
            "couldn\n",
            "couldn't\n",
            "didn\n",
            "didn't\n",
            "doesn\n",
            "doesn't\n",
            "hadn\n",
            "hadn't\n",
            "hasn\n",
            "hasn't\n",
            "haven\n",
            "haven't\n",
            "isn\n",
            "isn't\n",
            "ma\n",
            "mightn\n",
            "mightn't\n",
            "mustn\n",
            "mustn't\n",
            "needn\n",
            "needn't\n",
            "shan\n",
            "shan't\n",
            "shouldn\n",
            "shouldn't\n",
            "wasn\n",
            "wasn't\n",
            "weren\n",
            "weren't\n",
            "won\n",
            "won't\n",
            "wouldn\n",
            "wouldn't\n",
            "No. of stopwords:  179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "\n",
        "tagged_words = nltk.pos_tag(words)\n",
        "\n",
        "# Tagged word paragraph\n",
        "word_tags = []\n",
        "for tw in tagged_words:\n",
        "    word_tags.append(tw[0]+\"_\"+tw[1])\n",
        "\n",
        "tagged_paragraph = ' '.join(word_tags)\n",
        "print(tagged_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP2SOgWkDQ6W",
        "outputId": "1888caa4-9ddb-4377-924c-f9542840da17"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural_JJ language_NN processing_NN (_( NLP_NNP )_) is_VBZ an_DT interdisciplinary_JJ subfield_NN of_IN computer_NN science_NN and_CC linguistics_NNS ._. It_PRP is_VBZ p_JJ rimarily_RB concerned_VBN with_IN giving_VBG computers_NNS the_DT ability_NN to_TO support_VB and_CC manipulate_VB speech_NN ._. It_PRP involves_VBZ processing_VBG natural_JJ language_NN datasets_NNS ,_, such_JJ as_IN text_JJ corpora_NN or_CC speech_NN corpora_NNS ,_, using_VBG either_CC rule-based_JJ or_CC probabilistic_JJ (_( i.e_JJ ._. statistical_JJ and_CC ,_, most_RBS recently_RB ,_, neural_JJ network-based_JJ )_) machine_NN learning_VBG approaches_NNS ._. The_DT goal_NN is_VBZ a_DT computer_NN capable_NN of_IN ``_`` understanding_JJ ''_'' the_DT contents_NNS of_IN documents_NNS ,_, including_VBG the_DT contextual_JJ nuances_NNS of_IN the_DT language_NN within_IN them_PRP ._. The_DT technology_NN can_MD then_RB accurately_RB extract_JJ information_NN and_CC insights_NNS contained_VBN in_IN the_DT documents_NNS as_RB well_RB as_IN categorize_NN and_CC organize_VB the_DT documents_NNS themselves_PRP ._. Challenges_NNS in_IN natural_JJ language_NN processing_NN frequently_RB involve_VBP speech_NN recognition_NN ,_, natural-language_JJ understanding_NN ,_, and_CC natural-language_JJ generation_NN ._. History_NN of_IN natural_JJ language_NN processing-_JJ Natural_NNP language_NN processing_NN has_VBZ its_PRP$ roots_NNS in_IN the_DT 1950s_CD ._. Already_RB in_IN 1950_CD ,_, Alan_NNP Turing_NNP published_VBD an_DT article_NN titled_VBN ``_`` Computing_JJ Machinery_NN and_CC Intelligence_NNP ''_'' which_WDT proposed_VBD what_WP is_VBZ now_RB called_VBN the_DT Turing_NNP test_NN as_IN a_DT criterion_NN of_IN intelligence_NN ,_, though_RB at_IN the_DT time_NN that_WDT was_VBD not_RB articulated_VBN as_IN a_DT problem_NN separate_NN from_IN artificial_JJ intelligence_NN ._. The_DT proposed_JJ test_NN includes_VBZ a_DT task_NN that_WDT involves_VBZ the_DT automated_JJ interpretation_NN and_CC generation_NN of_IN natural_JJ language_NN ._.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T01VdjFnDReI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# pattern1 = \"had a pen\"\n",
        "pattern1 = \"1234 99 sus91\"\n",
        "# pattern1 = \"11a\"\n",
        "\n",
        "print(\"Occurences of any character: \",re.match(r\".+\",pattern1))\n",
        "print(\"Occurences of A_Za-z: \",re.search(r\"[a-z]+\",pattern1))\n",
        "print(\"Occurences of ab*: \",re.search(r\"ab?\",pattern1))\n",
        "\n",
        "if re.match(r\"[a-z]+\",pattern1) != None:\n",
        "    print(\"There is a match!\")\n",
        "else:\n",
        "    print(\"There is no match!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k63C4FDDrzm",
        "outputId": "1c7b8e65-88a2-4188-d150-59d7d8a39814"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Occurences of any character:  <re.Match object; span=(0, 13), match='1234 99 sus91'>\n",
            "Occurences of A_Za-z:  <re.Match object; span=(8, 11), match='sus'>\n",
            "Occurences of ab*:  None\n",
            "There is no match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern1 = \"Grapes are tasty\"\n",
        "pattern2 = \"Today I feel like crying.\"\n",
        "\n",
        "if re.match(r\"^Grapes\",pattern1):\n",
        "    print(\"Matches!\")\n",
        "else:\n",
        "    print(\"No Match!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0HWMUElGbai",
        "outputId": "e4d1e6aa-0ccf-4aad-93e0-20db0fe8fc7d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern1 = \"00I love Avengers\" #I love Justice League\n",
        "\n",
        "print(re.sub(r\"Avengers\",\"Justice League\",pattern1))\n",
        "\n",
        "print(re.sub(r\"[a-z]\",\"2\",pattern1,1,flags=re.I))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMJzzpbNF7ks",
        "outputId": "48eae64a-a491-47f0-d573-17283f53e4ad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00I love Justice League\n",
            "002 love Avengers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# initializing string\n",
        "test_str = \"Goerge is the best. Doing so for ! all good ;\"\n",
        "\n",
        "# printing original string\n",
        "print(\"The original string is : \" + test_str)\n",
        "\n",
        "# Removing punctuations in string\n",
        "# Using regex\n",
        "res = re.sub(r'[^\\w\\s]', '', test_str)\n",
        "\n",
        "# printing result\n",
        "print(\"The string after punctuation filter : \" + res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et_AXwQJIj5A",
        "outputId": "c9b66b70-dd10-4cac-ba84-fe69d490e436"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original string is : Goerge is the best. Doing so for ! all good ;\n",
            "The string after punctuation filter : Goerge is the best Doing so for  all good \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample string containing various elements\n",
        "sample_string = \"\"\"\n",
        "Hello, World!\n",
        "12345 - This is a sample string with some symbols: @#$%\n",
        "It contains numbers like 123 and 3.14, and alphabets like abc and XYZ.\n",
        "There are also newline characters\\nand\\ttab characters.\n",
        "It may contain email address of the form hetalg@regenesys.net.\n",
        "\"\"\"\n",
        "\n",
        "# Extract all words from the string\n",
        "words = re.findall(r'\\b\\w+\\b', sample_string)\n",
        "print(\"Words in the string:\", words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg_DydlMIlau",
        "outputId": "aad84bca-0a8e-4786-ed79-9ccdd4ee85fb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in the string: ['Hello', 'World', '12345', 'This', 'is', 'a', 'sample', 'string', 'with', 'some', 'symbols', 'It', 'contains', 'numbers', 'like', '123', 'and', '3', '14', 'and', 'alphabets', 'like', 'abc', 'and', 'XYZ', 'There', 'are', 'also', 'newline', 'characters', 'and', 'tab', 'characters', 'It', 'may', 'contain', 'email', 'address', 'of', 'the', 'form', 'hetalg', 'regenesys', 'net']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all numbers from the string\n",
        "numbers = re.findall(r'\\b\\d+\\b', sample_string)\n",
        "print(\"\\nNumbers in the string:\", numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMq46B_vN9S4",
        "outputId": "b8189b6f-8489-46b7-b00f-23510e9b0b41"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numbers in the string: ['12345', '123', '3', '14']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Replace all whitespace characters with a single space\n",
        "no_whitespace = re.sub(r'\\s+', ' ', sample_string)\n",
        "print(\"\\nString with single spaces:\", no_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI3Jm1Ki6dTk",
        "outputId": "117b7d29-8bf5-4809-f1c1-401439afd5ab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "String with single spaces:  Hello, World! 12345 - This is a sample string with some symbols: @#$% It contains numbers like 123 and 3.14, and alphabets like abc and XYZ. There are also newline characters and tab characters. It may contain email address of the form hetalg@regenesys.net. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all sentences from the string\n",
        "sentences = re.split(r'[.!?]', sample_string)\n",
        "print(\"\\nSentences in the string:\", sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W94LL8vD6VCw",
        "outputId": "ae62e7e4-55ea-446d-d99d-fe3c57fd1f50"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentences in the string: ['\\nHello, World', '\\n12345 - This is a sample string with some symbols: @#$%\\nIt contains numbers like 123 and 3', '14, and alphabets like abc and XYZ', '\\nThere are also newline characters\\nand\\ttab characters', '\\nIt may contain email address of the form hetalg@regenesys', 'net', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Remove all punctuation marks from the string\n",
        "no_punctuation = re.sub(r'[^\\w\\s]', '', sample_string)\n",
        "print(\"\\nString without punctuation marks:\", no_punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-8VC1iz6YVc",
        "outputId": "8b41265a-805b-4ef4-9c0c-3a84c65a91c2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "String without punctuation marks: \n",
            "Hello World\n",
            "12345  This is a sample string with some symbols \n",
            "It contains numbers like 123 and 314 and alphabets like abc and XYZ\n",
            "There are also newline characters\n",
            "and\ttab characters\n",
            "It may contain email address of the form hetalgregenesysnet\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all email addresses in the string (basic email pattern)\n",
        "email_addresses = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', sample_string)\n",
        "print(\"\\nEmail addresses in the string:\", email_addresses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxoxvZMS6baU",
        "outputId": "ce5f8bf9-c241-4cb0-b647-2e4c699ad3d5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Email addresses in the string: ['hetalg@regenesys.net']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHQD-JBC6n08"
      },
      "execution_count": 46,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb2581d2313c8de5ff979f59992136b7cd0b4a115e62fef02542a0c9e049ace1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}